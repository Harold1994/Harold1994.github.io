<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLlib-分类回归 | lyyourc</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="stylesheet" href="/css/app.css">
  <!-- <link rel='stylesheet' href='http://fonts.useso.com/css?family=Source+Code+Pro'> -->
  
</head>

<body>
  <nav class="app-nav">
  
    
      <a href="/.">home</a>
    
  
    
      <a href="/archives">archive</a>
    
  
    
      <a href="/atom.xml">rss</a>
    
  
</nav>

  <main class="post">
  <article>
  <h1 class="article-title">
    <a href="/2018/06/28/MLlib-分类和回归1/">MLlib-分类回归</a>
  </h1>

  <section class="article-meta">
    <p class="article-date">June 28 2018</p>
  </section>

  <section class="article-entry">
    <h4 id="一、分类"><a href="#一、分类" class="headerlink" title="一、分类"></a>一、分类</h4><p><strong>1.逻辑回归</strong></p>
<p>逻辑回归是预测分类反应的流行方法。 <a href="https://en.wikipedia.org/wiki/Generalized_linear_model" target="_blank" rel="noopener">广义线性模型</a>的一个特例是预测结果的可能性。 在spark.ml逻辑回归中可以使用二项式逻辑回归来预测二进制结果，也可以通过使用多项Logistic回归来预测多类结果。 使用系列参数在这两种算法之间进行选择，或者将其设置为未设置，Spark将推断出正确的变体。</p>
<a id="more"></a> 
<p>通过将家族参数设置为“多项式”，可以将多项Logistic回归用于二进制分类。它将产生两组系数和两个截距。</p>
<p>当在具有常量非零列的数据集上对LogisticRegressionModel进行拟合时，Spark MLlib为常数非零列输出零系数。此行为与R glmnet相同，但与LIBSVM不同。</p>
<ul>
<li><p>二项式逻辑回归</p>
<p>以下示例显示了如何用弹性网络正则化来训练二项分类的二项式和多项Logistic回归模型。 elasticNetParam对应于α，regParam对应于λ（正则化参数（泛化能力），<strong>加正则化的前提是特征值要进行归一化</strong>）。</p>
<blockquote>
<p>弹性网络是一种使用 L1， L2 范数作为先验正则项训练的线性回归模型。 这种组合允许学习到一个只有少量参数是非零稀疏的模型，就像 Lasso 一样，但是它仍然保持一些像 Ridge 的正则性质。我们可利用 l1_ratio 参数控制 L1 和 L2 的凸组合。</p>
<p>弹性网络在很多特征互相联系的情况下是非常有用的。Lasso 很可能只随机考虑这些特征中的一个，而弹性网络更倾向于选择两个。</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">LogisticRegressionWithElasticNetExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .appName(<span class="string">"LogisticRegressionWithElasticNetExample"</span>)</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> training = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lr = <span class="keyword">new</span> <span class="type">LogisticRegression</span>()</span><br><span class="line">      .setMaxIter(<span class="number">10</span>)<span class="comment">//最大迭代次数</span></span><br><span class="line">      .setRegParam(<span class="number">0.3</span>)<span class="comment">//学习速率</span></span><br><span class="line">      .setElasticNetParam(<span class="number">0.8</span>)<span class="comment">//结构化参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lrModel = lr.fit(training)</span><br><span class="line">    <span class="comment">//打印训练出来的系数矩阵和偏置</span></span><br><span class="line">    println(<span class="string">s"Coefficients: <span class="subst">$&#123;lrModel.coefficients&#125;</span> Intercept: <span class="subst">$&#123;lrModel.intercept&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mlr = <span class="keyword">new</span> <span class="type">LogisticRegression</span>()</span><br><span class="line">      .setMaxIter(<span class="number">10</span>)</span><br><span class="line">      .setRegParam(<span class="number">0.3</span>)</span><br><span class="line">      .setElasticNetParam(<span class="number">0.8</span>)</span><br><span class="line">      .setFamily(<span class="string">"multinomial"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mlrModel = mlr.fit(training)</span><br><span class="line">    <span class="comment">// Print the coefficients and intercepts for logistic regression with multinomial family</span></span><br><span class="line">    println(<span class="string">s"Multinomial coefficients: <span class="subst">$&#123;mlrModel.coefficientMatrix&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"Multinomial intercepts: <span class="subst">$&#123;mlrModel.interceptVector&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>逻辑回归的spark.ml实现也支持在训练集中提取模型的摘要。 请注意，在BinaryLogisticRegressionSummary中存储为DataFrame的预测和度量标注为@transient，因此仅在驱动程序上可用。</p>
<p><a href="http://spark.apache.org/docs/2.1.0/api/scala/index.html#org.apache.spark.ml.classification.LogisticRegressionTrainingSummary" target="_blank" rel="noopener">LogisticRegressionTrainingSummary</a>为<a href="http://spark.apache.org/docs/2.1.0/api/scala/index.html#org.apache.spark.ml.classification.LogisticRegressionModel" target="_blank" rel="noopener">LogisticRegressionModel</a>提供了一个摘要。 目前，只支持二进制分类，必须将摘要显式转换为<a href="http://spark.apache.org/docs/2.1.0/api/scala/index.html#org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummary" target="_blank" rel="noopener">BinaryLogisticRegressionTrainingSummary</a>。 当支持多类分类时，这可能会发生变化。</p>
<p>继续前面的例子：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//从之前返回的模型实例中获取summary</span></span><br><span class="line">   <span class="keyword">import</span> spark.implicits._</span><br><span class="line">  </span><br><span class="line">   <span class="keyword">val</span> trainingSummary = lrModel.binarySummary</span><br><span class="line">   <span class="comment">//获取每次迭代的目标</span></span><br><span class="line">   <span class="keyword">val</span> objectiveHistory = trainingSummary.objectiveHistory</span><br><span class="line">   println(<span class="string">"objectiveHistory:"</span>)<span class="comment">//打印损失</span></span><br><span class="line">   objectiveHistory.foreach(loss =&gt; println(loss))</span><br><span class="line">   <span class="comment">//获取有用的度量标准，以判断测试数据的性能。</span></span><br><span class="line">   <span class="comment">// 我们将该summary投射到BinaryLogisticRegressionSummary，因为该问题是二元分类问题。</span></span><br><span class="line">  </span><br><span class="line">   <span class="keyword">val</span> roc = trainingSummary.roc</span><br><span class="line">   roc.show()</span><br><span class="line">   println(<span class="string">s"Area under ROC: <span class="subst">$&#123;trainingSummary.areaUnderROC&#125;</span>"</span>)</span><br><span class="line">  </span><br><span class="line">   <span class="comment">//设置模型阈值来最大化F1</span></span><br><span class="line">   <span class="keyword">val</span> fMeasure = trainingSummary.fMeasureByThreshold</span><br><span class="line">   <span class="keyword">val</span> maxFMeasure = fMeasure.select((<span class="string">"F-Measure"</span>)).head().getDouble(<span class="number">0</span>)</span><br><span class="line">   <span class="keyword">val</span> bestThreshold = fMeasure.where($<span class="string">"F-Measure"</span> === maxFMeasure)</span><br><span class="line">     .select(<span class="string">"threshold"</span>).head().getDouble(<span class="number">0</span>)</span><br><span class="line">   lrModel.setThreshold(bestThreshold)</span><br><span class="line">   spark.stop()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>2. 决策树分类器</strong></p>
<p>决策树是一种流行的分类和回归方法。以下示例以LibSVM格式加载数据集，将其拆分为训练和测试集，在第一个数据集上训练，然后对所保留的测试集进行评估。 我们使用两个transformer来准备数据; 这些帮助索引类别的标签和分类功能，添加元数据到决策树算法可以识别的DataFrame。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DecisionTreeClassificationExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="string">"DecisionTreeClassificationExample"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    <span class="comment">//对label进行索引</span></span><br><span class="line">    <span class="keyword">val</span> labelIndexer = <span class="keyword">new</span> <span class="type">StringIndexer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"label"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"indexedLabel"</span>)</span><br><span class="line">      .fit(data)</span><br><span class="line">    <span class="comment">//自动确定哪些功能是分类的，并将原始值转换为类别索引</span></span><br><span class="line">    <span class="keyword">val</span> featureIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"features"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setMaxCategories(<span class="number">4</span>)</span><br><span class="line">      .fit(data)</span><br><span class="line">    <span class="comment">//将数据集分为训练集和测试集</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> dt = <span class="keyword">new</span> <span class="type">DecisionTreeClassifier</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"indexedLabel"</span>)</span><br><span class="line">      .setFeaturesCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">    <span class="comment">//将预测出来的label还原为原来对应的label</span></span><br><span class="line">    <span class="keyword">val</span> loabelConvertor = <span class="keyword">new</span> <span class="type">IndexToString</span>()</span><br><span class="line">      .setInputCol(<span class="string">"prediction"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"predictedLabel"</span>)</span><br><span class="line">      .setLabels(labelIndexer.labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>()</span><br><span class="line">      .setStages(<span class="type">Array</span>(labelIndexer, featureIndexer, dt, loabelConvertor))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line">    predictions.select(<span class="string">"predictedLabel"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"indexedLabel"</span>)</span><br><span class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</span><br><span class="line">      .setMetricName(<span class="string">"accuracy"</span>)</span><br><span class="line">    <span class="keyword">val</span> accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    println(<span class="string">"Test Error = "</span> + (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> treeModel = model.stages(<span class="number">2</span>).asInstanceOf[<span class="type">DecisionTreeClassificationModel</span>]</span><br><span class="line">    println(<span class="string">"Learned classification tree model:\n"</span> + treeModel.toDebugString)</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>3. 随机森林分类</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RandomForestClassifierExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .appName(<span class="string">"VectorIndexerExample"</span>)</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> labelIndexer = <span class="keyword">new</span> <span class="type">StringIndexer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"label"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"indexedLabel"</span>)</span><br><span class="line">      .fit(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> featureIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"features"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setMaxCategories(<span class="number">4</span>)</span><br><span class="line">      .fit(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rf = <span class="keyword">new</span> <span class="type">RandomForestClassifier</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"indexedLabel"</span>)</span><br><span class="line">      .setFeaturesCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setNumTrees(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> labelConverter = <span class="keyword">new</span> <span class="type">IndexToString</span>()</span><br><span class="line">      .setInputCol(<span class="string">"prediction"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"predictedLabel"</span>)</span><br><span class="line">      .setLabels(labelIndexer.labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>()</span><br><span class="line">      .setStages(<span class="type">Array</span>(labelIndexer, featureIndexer, rf, labelConverter))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line">    predictions.select(<span class="string">"predictedLabel"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"indexedLabel"</span>)</span><br><span class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</span><br><span class="line">      .setMetricName(<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    println(<span class="string">"Test Error = "</span> + (<span class="number">1.0</span> - accuracy))</span><br><span class="line">    <span class="keyword">val</span> rfModel = model.stages(<span class="number">2</span>).asInstanceOf[<span class="type">RandomForestClassificationModel</span>]</span><br><span class="line">    println(<span class="string">"Learned classification forest model:\n"</span> + rfModel.toDebugString)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>4. 梯度增强树分类器</strong></p>
<p>梯度增强树（GBT）是使用决策树组合的流行分类和回归方法。以下示例以LibSVM格式加载数据集，将其分解为训练和测试集，在第一个数据集上训练，然后在被测试的集合上进行训练。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> gbt = <span class="keyword">new</span> <span class="type">GBTClassifier</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"indexedLabel"</span>)</span><br><span class="line">      .setFeaturesCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setMaxIter(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><strong>5. 多层感知器分类器</strong></p>
<p>多层感知器分类器（Multilayer perceptron classifier）是基于<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network" target="_blank" rel="noopener">前馈人工神经网络</a>的分类器。 MLPC由多层节点组成。 每个层完全连接到网络中的下一层。 输入层中的节点表示输入数据。 所有其他节点通过输入与节点权重ww和偏差bb的线性组合将输入映射到输出，并应用激活功能。 这可以用矩阵形式写入具有K + 1层的MLPC，如下所示：</p>
<p>​                                         $y(x) = f_K(…f_2(w_2^Tf_1(w_1^Tx + b1) + b2) … +b_K)$</p>
<p>中间层节点使用Sigmoid（logistic）函数：</p>
<p>​                                                             $f(z_i) = \frac1{1 + e^{-z_i}}$</p>
<p>输出层节点使用softmax函数：</p>
<p>​                                                             $f(z_i) = \frac {e^{z_i}}{\sum_{k=1}^{N}e^{z_k}}$</p>
<p>输出层中的节点数N对应于类的数量。MLPC采用反向传播来学习模型。我们使用物流损失函数进行优化和L-BFGS作为优化程序。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MultilayerPerceptronClassifierExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .appName(<span class="string">"MultilayerPerceptronClassifierExample"</span>)</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> splits = data.randomSplit(<span class="type">Array</span>(<span class="number">0.6</span>, <span class="number">0.4</span>), seed = <span class="number">1234</span>L)</span><br><span class="line">    <span class="keyword">val</span> train = splits(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">val</span> test = splits(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">//    设置神经网络的层数</span></span><br><span class="line">    <span class="comment">//    输入层有4个神经元、两个隐含层分别有5和4个神经元，输出层有3个</span></span><br><span class="line">    <span class="keyword">val</span> layers = <span class="type">Array</span>[<span class="type">Int</span>](<span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> trainer = <span class="keyword">new</span> <span class="type">MultilayerPerceptronClassifier</span>()</span><br><span class="line">      .setLayers(layers)</span><br><span class="line">      .setBlockSize(<span class="number">128</span>)</span><br><span class="line">      .setSeed(<span class="number">1234</span>L)</span><br><span class="line">      .setMaxIter(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> model = trainer.fit(train)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result = model.transform(test)</span><br><span class="line">    <span class="keyword">val</span> predictionAndLabel = result.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>)</span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</span><br><span class="line">      .setMetricName(<span class="string">"accuracy"</span>)</span><br><span class="line">    println(<span class="string">"Test set accuracy = "</span> + evaluator.evaluate(predictionAndLabel))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>6. One-vs-Rest classifier</strong>一对全分类器</p>
<p><a href="http://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest" target="_blank" rel="noopener">OneVsRest</a>将一个给定的二分类算法有效地扩展到多分类问题应用中，也叫做“One-vs-All.”算法。OneVsRest是一个Estimator。它采用一个基础的Classifier然后对于k个类别分别创建二分类问题。类别i的二分类分类器用来预测类别为i还是不为i，即将i类和其他类别区分开来。最后，通过依次对k个二分类分类器进行评估，取置信最高的分类器的标签作为i类别的标签。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">OneVsRestExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="string">"OneVsRestExample"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> inputData = spark.read.format(<span class="string">"libsvm"</span>)</span><br><span class="line">      .load(<span class="string">"data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(train, test) = inputData.randomSplit(<span class="type">Array</span>(<span class="number">0.8</span>, <span class="number">0.2</span>))</span><br><span class="line">    <span class="keyword">val</span> classifier = <span class="keyword">new</span> <span class="type">LogisticRegression</span>()</span><br><span class="line">      .setMaxIter(<span class="number">10</span>)</span><br><span class="line">      .setTol((<span class="number">1E-6</span>)) <span class="comment">//迭代算法的收敛性</span></span><br><span class="line">      .setFitIntercept(<span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ovr = <span class="keyword">new</span> <span class="type">OneVsRest</span>().setClassifier(classifier)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ovrModel = ovr.fit(train)</span><br><span class="line">    <span class="keyword">val</span> predictions = ovrModel.transform(test)</span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</span><br><span class="line">      .setMetricName(<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    println(<span class="string">s"Test Error = <span class="subst">$&#123;1 - accuracy&#125;</span>"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>7. 朴素贝叶斯分类器</strong></p>
<p>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。</p>
<p>朴素贝叶斯的思想基础是这样的：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，在没有其它可用信息下，我们会选择条件概率最大的类别作为此待分类项应属的类别。</p>
<p>朴素贝叶斯分类的正式定义如下：</p>
<p>1、设<img src="http://latex.codecogs.com/gif.latex?x%20=%20%5Cleft%5C%7B%20%7B%7Ba_1%7D,%7Ba_2%7D,%20%5Cldots%20,%7Ba_m%7D%7D%20%5Cright%5C%7D" alt="img"> 为一个待分类项，而每个a为x的一个特征属性。</p>
<p>2、有类别集合<img src="http://latex.codecogs.com/gif.latex?C%20=%20%5Cleft%5C%7B%20%7B%7By_1%7D,%7By_2%7D,%20%5Cldots%20,%7By_n%7D%7D%20%5Cright%5C%7D" alt="img"> 。</p>
<p>3、计算<img src="http://latex.codecogs.com/gif.latex?P%5Cleft(%20%7B%7By_1%7D%5Cleft%7C%20x%20%5Cright.%7D%20%5Cright" alt="img">,P(%7By_2%7D%5Cleft%7C%20x%20%5Cright.),%20%5Cldots%20,P(%7By_n%7D%5Cleft%7C%20x%20%5Cright.)) 。</p>
<p>4、如果<img src="http://latex.codecogs.com/gif.latex?P%5Cleft(%20%7B%7By_k%7D%5Cleft%7C%20x%20%5Cright.%7D%20%5Cright" alt="img">%20=%20max%5C%7B%20P%5Cleft(%20%7B%7By_1%7D%5Cleft%7C%20x%20%5Cright.%7D%20%5Cright),P%5Cleft(%20%7B%7By_2%7D%5Cleft%7C%20x%20%5Cright.%7D%20%5Cright),%20%5Cldots%20,P%5Cleft(%20%7B%7By_n%7D%5Cleft%7C%20x%20%5Cright.%7D%20%5Cright)%5C%7D) ，则<img src="http://latex.codecogs.com/gif.latex?x%20%5Cin%20%7By_k%7D" alt="img"> 。</p>
<p>那么现在的关键就是如何计算第3步中的各个条件概率。我们可以这么做：</p>
<p>1、找到一个已知分类的待分类项集合，这个集合叫做训练样本集。</p>
<p>2、统计得到在各类别下各个特征属性的条件概率估计。即<img src="http://latex.codecogs.com/gif.latex?P(%7Ba_1%7D%7B%5Cleft%7C%20y%20%5Cright._1%7D" alt="img">,P(%7Ba_2%7D%7B%5Cleft%7C%20y%20%5Cright._1%7D),%20%5Cldots%20,P(%7Ba_m%7D%5Cleft%7C%20%7B%7By_1%7D%7D%20%5Cright.);P(%7Ba_1%7D%7B%5Cleft%7C%20y%20%5Cright._2%7D),P(%7Ba_2%7D%7B%5Cleft%7C%20y%20%5Cright._2%7D),%20%5Cldots%20,P(%7Ba_m%7D%5Cleft%7C%20%7B%7By_2%7D%7D%20%5Cright.);%20%5Cldots%20;P(%7Ba_1%7D%7B%5Cleft%7C%20y%20%5Cright._n%7D),P(%7Ba_2%7D%7B%5Cleft%7C%20y%20%5Cright._n%7D),%20%5Cldots%20,P(%7Ba_m%7D%7B%5Cleft%7C%20y%20%5Cright._n%7D)) </p>
<p>3、如果各个特征属性是条件独立的，则根据贝叶斯定理有如下推导：</p>
<p><img src="http://latex.codecogs.com/gif.latex?P%5Cleft(%20%7B%7By_i%7D%5Cleft%7C%20x%20%5Cright.%7D%20%5Cright" alt="img">%20=%20%5Cfrac%7B%7BP(x%5Cleft%7C%20%7B%7By_i%7D)P(%7By_i%7D)%7D%20%5Cright.%7D%7D%7B%7BP(x)%7D%7D) </p>
<p>因为分母对于所有类别为常数，因为我们只要将分子最大化皆可。又因为各特征属性是条件独立的，所以有：</p>
<p><img src="http://latex.codecogs.com/gif.latex?P%5Cleft(%20%7Bx%5Cleft%7C%20%7B%7By_i%7D%7D%20%5Cright.%7D%20%5Cright" alt="img">P%5Cleft(%20%7B%7By_i%7D%7D%20%5Cright)%20=%20P%5Cleft(%20%7B%7Ba_1%7D%5Cleft%7C%20%7B%7By_i%7D%7D%20%5Cright.%7D%20%5Cright)P(%7Ba_2%7D%5Cleft%7C%20%7B%7By_i%7D%7D%20%5Cright.)%20%5Cldots%20P(%7Ba_m%7D%5Cleft%7C%20%7B%7By_i%7D%7D%20%5Cright.)%20=%20P%5Cleft(%20%7B%7By_i%7D%7D%20%5Cright)%5Cprod%20P%5Cleft(%20%7B%7Ba_j%7D%5Cleft%7C%20%7B%7By_i%7D%7D%20%5Cright.%7D%20%5Cright)) </p>
<p>spark.ml现在支持多项朴素贝叶斯和伯努利朴素贝叶斯。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">NaiveBayesExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="string">"OneVsRestExample"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>,<span class="number">0.3</span>), seed = <span class="number">1234</span>L)</span><br><span class="line">    <span class="keyword">val</span> model = <span class="keyword">new</span> <span class="type">NaiveBayes</span>()</span><br><span class="line">      .fit(trainingData)</span><br><span class="line">    <span class="keyword">val</span> predictions = model.transform(testData)</span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</span><br><span class="line">        .setLabelCol(<span class="string">"label"</span>)</span><br><span class="line">        .setPredictionCol(<span class="string">"prediction"</span>)</span><br><span class="line">       .setMetricName(<span class="string">"accuracy"</span>)</span><br><span class="line">    <span class="keyword">val</span> accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    println(<span class="string">"Test set accuracy: "</span> + accuracy)</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="二、回归"><a href="#二、回归" class="headerlink" title="二、回归"></a>二、回归</h4><p><strong>1.线性回归</strong></p>
<p>以下示例演示了训练弹性网络正则化线性回归模型并提取模型汇总统计量。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lr= <span class="keyword">new</span> <span class="type">LinearRegression</span>()</span><br><span class="line">  .setMaxIter(<span class="number">10</span>)</span><br><span class="line">  .setRegParam(<span class="number">0.3</span>)</span><br><span class="line">  .setElasticNetParam(<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> lrModel = lr.fit(training)</span><br><span class="line">println(<span class="string">s"Coefficients : <span class="subst">$&#123;lrModel.coefficients&#125;</span> Intercept: <span class="subst">$&#123;lrModel.intercept&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> trainingSummary = lrModel.summary</span><br><span class="line">println(<span class="string">s"num iterations : <span class="subst">$&#123;trainingSummary.totalIterations&#125;</span>"</span>)</span><br><span class="line">println(<span class="string">s"objectiveHistory : <span class="subst">$&#123;trainingSummary.objectiveHistory.mkString(", ")&#125;</span>"</span>)</span><br><span class="line">trainingSummary.residuals.show()<span class="comment">//残差</span></span><br><span class="line">println(<span class="string">s"RMSE: <span class="subst">$&#123;trainingSummary.rootMeanSquaredError&#125;</span>"</span>)<span class="comment">//均方误差</span></span><br><span class="line">println(<span class="string">s"r2: <span class="subst">$&#123;trainingSummary.r2&#125;</span>"</span>)<span class="comment">//决定系数</span></span><br></pre></td></tr></table></figure>
<p><strong>2.广义线性回归GLM</strong></p>
<p>与线性回归假设输出服从高斯分布不同，广义线性模型（GLMs）指定线性模型的因变量$Y_i$服从指数型分布。Spark的GeneralizedLinearRegression接口允许指定GLMs包括线性回归、泊松回归、逻辑回归等来处理多种预测问题。目前 spark.ml仅支持指数型分布家族中的一部分类型，如下：</p>
<table>
<thead>
<tr>
<th>分布类型</th>
<th>应变量类型</th>
<th>支持连接函数类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>高斯分布</td>
<td>连续</td>
<td>Identity*,  Log,  Inverse</td>
</tr>
<tr>
<td>二项分布</td>
<td>二值</td>
<td>Logit*, Probit, CLogLog</td>
</tr>
<tr>
<td>泊松分布</td>
<td>计数</td>
<td>Log*, Identity, Sqrt</td>
</tr>
<tr>
<td>伽马分布</td>
<td>连续</td>
<td>Inverse*, Idenity, Log</td>
</tr>
</tbody>
</table>
<blockquote>
<p>logit、probit以及cloglog都是统计变换，目的是将二项分布数据转换为一种形式，以便能用线性模型估计直接估计模型的参数。</p>
</blockquote>
<ul>
<li>注意目前Spark在 <code>GeneralizedLinearRegression</code>仅支持最多4096个特征，如果特征超过4096个将会引发异常。对于线性回归和逻辑回归，如果模型特征数量会不断增长，则可通过 LinearRegression 和LogisticRegression来训练。</li>
</ul>
<p>park的GeneralizedLinearRegression接口提供汇总统计来诊断GLM模型的拟合程度，包括残差、p值、残差、Akaike信息准则及其它。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">GeneralizedLinearRegressionExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="string">"GeneralizedLinearRegressionExample"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> dataset = spark.read.format(<span class="string">"libsvm"</span>)</span><br><span class="line">      .load(<span class="string">"data/mllib/sample_linear_regression_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> glr = <span class="keyword">new</span> <span class="type">GeneralizedLinearRegression</span>()</span><br><span class="line">      .setFamily(<span class="string">"gaussian"</span>)<span class="comment">//模型中使用的误差分布类型。</span></span><br><span class="line">      .setLink(<span class="string">"identity"</span>)<span class="comment">//连接函数名，描述线性预测器和分布函数均值之间关系</span></span><br><span class="line">      .setMaxIter(<span class="number">10</span>)</span><br><span class="line">      .setRegParam(<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span>  model = glr.fit(dataset)</span><br><span class="line"><span class="comment">//  输出权值向量和截距</span></span><br><span class="line">    println(<span class="string">s"Coefficients: <span class="subst">$&#123;model.coefficients&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"Intercept: <span class="subst">$&#123;model.intercept&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> summary = model.summary</span><br><span class="line">    println(<span class="string">s"Coefficient Standart errors: <span class="subst">$&#123;summary.coefficientStandardErrors.mkString(", ")&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"T Values: <span class="subst">$&#123;summary.tValues.mkString(",")&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"P Values: <span class="subst">$&#123;summary.pValues.mkString(",")&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"Dispersion: <span class="subst">$&#123;summary.dispersion&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"Null Deviance: <span class="subst">$&#123;summary.nullDeviance&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"Residual Degree Of Freedom Null: <span class="subst">$&#123;summary.residualDegreeOfFreedomNull&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"Deviance: <span class="subst">$&#123;summary.deviance&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"Residual Degree Of Freedom: <span class="subst">$&#123;summary.residualDegreeOfFreedom&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"AIC: <span class="subst">$&#123;summary.aic&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">"Deviance Residuals: "</span>)</span><br><span class="line">    summary.residuals().show()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>3.决策树回归</strong></p>
<p> 决策树以及其集成算法是机器学习分类和回归问题中非常流行的算法。因其易解释性、可处理类别特征、易扩展到多分类问题、不需特征缩放等性质被广泛使用。树集成算法如随机森林以及boosting算法几乎是解决分类和回归问题中表现最优的算法。</p>
<p>​       决策树是一个贪心算法递归地将特征空间划分为两个部分，在同一个叶子节点的数据最后会拥有同样的标签。每次划分通过贪心的以获得最大信息增益为目的，从可选择的分裂方式中选择最佳的分裂节点。节点不纯度有节点所含类别的同质性来衡量。工具提供为分类提供两种不纯度衡量（基尼不纯度和熵），为回归提供一种不纯度衡量（方差）。</p>
<p>​       spark.ml支持二分类、多分类以及回归的决策树算法，适用于连续特征以及类别特征。另外，对于分类问题，工具可以返回属于每种类别的概率（类别条件概率），对于回归问题工具可以返回预测在偏置样本上的方差。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DecisionTreeRegressionExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="string">"DecisionTreeClassificationExample"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    <span class="keyword">val</span> featureIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"features"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setMaxCategories(<span class="number">4</span>)</span><br><span class="line">      .fit(data)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> dt = <span class="keyword">new</span> <span class="type">DecisionTreeRegressor</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"label"</span>)</span><br><span class="line">      .setFeaturesCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>()</span><br><span class="line">      .setStages(<span class="type">Array</span>(featureIndexer,dt))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> model = pipeline.fit(trainingData)</span><br><span class="line">    <span class="keyword">val</span> predictions = model.transform(testData)</span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>,<span class="string">"label"</span>,<span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">RegressionEvaluator</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"label"</span>)</span><br><span class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</span><br><span class="line">      .setMetricName(<span class="string">"rmse"</span>)</span><br><span class="line">    <span class="keyword">val</span> rmse = evaluator.evaluate(predictions)</span><br><span class="line">    println(<span class="string">"Root Mean Squared Error (RMSE) on test data = "</span> + rmse)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> treeModel = model.stages(<span class="number">1</span>).asInstanceOf[<span class="type">DecisionTreeRegressionModel</span>]</span><br><span class="line">    println(<span class="string">"Learned regression tree model:\n"</span> + treeModel.toDebugString)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>4.随机森林回归</strong></p>
<p>​       随机森林是决策树的集成算法。随机森林包含多个决策树来降低过拟合的风险。随机森林同样具有易解释性、可处理类别特征、易扩展到多分类问题、不需特征缩放等性质。</p>
<p>​       随机森林分别训练一系列的决策树，所以训练过程是并行的。因算法中加入随机过程，所以每个决策树又有少量区别。通过合并每个树的预测结果来减少预测的方差，提高在测试集上的性能表现。</p>
<p>随机性体现：</p>
<ol>
<li>每次迭代时，对原始数据进行二次抽样来获得不同的训练数据。</li>
<li>对于每个树节点，考虑不同的随机特征子集来进行分裂。</li>
</ol>
<p>除此之外，决策时的训练过程和单独决策树训练过程相同。对新实例进行预测时，随机森林需要整合其各个决策树的预测结果。回归和分类问题的整合的方式略有不同。分类问题采取投票制，每个决策树投票给一个类别，获得最多投票的类别为最终结果。回归问题每个树得到的预测结果为实数，最终的预测结果为各个树预测结果的平均值。</p>
<p>spark.ml支持二分类、多分类以及回归的随机森林算法，适用于连续特征以及类别特征。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RandomForestRegressorExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="string">"DecisionTreeClassificationExample"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    <span class="keyword">val</span> featureIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"features"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setMaxCategories(<span class="number">4</span>)</span><br><span class="line">      .fit(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rf = <span class="keyword">new</span> <span class="type">RandomForestRegressor</span>()</span><br><span class="line">      .setFeaturesCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setLabelCol(<span class="string">"label"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>()</span><br><span class="line">      .setStages(<span class="type">Array</span>(featureIndexer, rf))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> model = pipeline.fit(trainingData)</span><br><span class="line">    <span class="keyword">val</span> predictions = model.transform(testData)</span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">RegressionEvaluator</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"label"</span>)</span><br><span class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</span><br><span class="line">      .setMetricName(<span class="string">"rmse"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rmse = evaluator.evaluate(predictions)</span><br><span class="line">    println(<span class="string">s"Root Mean Squared Errpes:\n <span class="subst">$&#123;rmse&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rfModel = model.stages(<span class="number">1</span>).asInstanceOf[<span class="type">RandomForestRegressionModel</span>]</span><br><span class="line">    println(<span class="string">"Learned regression forest model:\n"</span> + rfModel.toDebugString)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>5.梯度增强树回归</strong></p>
<p>  梯度提升树是一种决策树的集成算法。它通过反复迭代训练决策树来最小化损失函数。决策树类似，梯度提升树具有可处理类别特征、易扩展到多分类问题、不需特征缩放等性质。Spark.ml通过使用现有<a href="http://spark.apache.org/docs/latest/mllib-decision-tree.html" target="_blank" rel="noopener">decision tree</a>工具来实现。</p>
<p>​       梯度提升树依次迭代训练一系列的决策树。在一次迭代中，算法使用现有的集成来对每个训练实例的类别进行预测，然后将预测结果与真实的标签值进行比较。通过重新标记，来赋予预测结果不好的实例更高的权重。所以，在下次迭代中，决策树会对先前的错误进行修正。</p>
<p>​       对实例标签进行重新标记的机制由损失函数来指定。每次迭代过程中，梯度迭代树在训练数据上进一步减少损失函数的值。spark.ml为分类问题提供一种损失函数（Log Loss），为回归问题提供两种损失函数（平方误差与绝对误差）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">GradientBoostedTreeRegressorExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="string">"DecisionTreeClassificationExample"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    <span class="keyword">val</span> featureIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"features"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setMaxCategories(<span class="number">4</span>)</span><br><span class="line">      .fit(data)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line">    <span class="keyword">val</span> gbt = <span class="keyword">new</span> <span class="type">GBTRegressor</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"label"</span>)</span><br><span class="line">      .setFeaturesCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line">      .setMaxIter(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>()</span><br><span class="line">      .setStages(<span class="type">Array</span>(featureIndexer, gbt))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> model = pipeline.fit(trainingData)</span><br><span class="line">    <span class="keyword">val</span> predictions = model.transform(testData)</span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>,<span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">RegressionEvaluator</span>()</span><br><span class="line">      .setLabelCol(<span class="string">"label"</span>)</span><br><span class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</span><br><span class="line">      .setMetricName(<span class="string">"rmse"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rmse = evaluator.evaluate(predictions)</span><br><span class="line">    println(<span class="string">"Root Mean Squared Error (RMSE) on test data = "</span> + rmse)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> gbtModel = model.stages(<span class="number">1</span>).asInstanceOf[<span class="type">GBTRegressionModel</span>]</span><br><span class="line">    println(<span class="string">"Learned regression GBT model:\n"</span> + gbtModel.toDebugString)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  </section>
</article>

  <div class="sharing grid">
  <section class="profile grid-item grid">
    <img class="avatar" src="http://7xrcp8.com1.z0.glb.clouddn.com/avatar.png" alt="avatar" />
    <div class="grid-item">
      <p class="title"> lyyourc </p>
      <p class="subtitle"> You Are The JavaScript In My HTML </p>
    <div>
  </section>

  <section class="share-btns">
    <!-- <p> share it if you like it~ </p> -->
    <a
  class="twitter-share-button"
  data-size="large"
  data-via="DrakeLeung"
  href="https://twitter.com/intent/tweet?text= id="一、分类"><a href=""
>
  Tweet
</a>

<script>
  window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  js.async = true;
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));
</script>

  </section>
</div>


  
    
<section class="article-comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

<script>
  var disqus_shortname = 'drakeleung';
  
  var disqus_url = '//harold.me/2018/06/28/MLlib-分类和回归1/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


  
</main>

</body>
</html>
