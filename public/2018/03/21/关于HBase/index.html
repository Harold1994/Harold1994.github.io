<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>关于HBase | lyyourc</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="stylesheet" href="/css/app.css">
  <!-- <link rel='stylesheet' href='http://fonts.useso.com/css?family=Source+Code+Pro'> -->
  
</head>

<body>
  <nav class="app-nav">
  
    
      <a href="/.">home</a>
    
  
    
      <a href="/archives">archive</a>
    
  
    
      <a href="/atom.xml">rss</a>
    
  
</nav>

  <main class="post">
  <article>
  <h1 class="article-title">
    <a href="/2018/03/21/关于HBase/">关于HBase</a>
  </h1>

  <section class="article-meta">
    <p class="article-date">March 21 2018</p>
  </section>

  <section class="article-entry">
    <p>HBase是一个在HDFS上开发的面向列的分布式数据库,可以用来实时的随机访问超大规模数据集,它自底向上的进行构建,能够简单的通过增加节点来达到线性扩展,HBase不是关系型数据库,不支持SQL,它能在廉价的硬件构成的集群上管理超大规模的稀疏表.</p>
<h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><p>应用将数据存放在带标签的表中,表格的”单元格”由行和列的坐标交叉决定,是<em>有版本</em>的,版本号默认是自动分配的,为插入单元格的时间戳.单元格内容是未解释的字节数组.<br> <a id="more"></a></p>
<p><img src="http://p5s7d12ls.bkt.clouddn.com/18-3-21/37375528.jpg" alt=""></p>
<p>表中行的键也是字节数组,行根据行的键进行排序,排序根据字节序进行,所有对表的访问都要通过表的主键,HBase不支持表中的其他列建立索引.<br>行中的列被分为列族,同一个列族成员具有相同的前缀,info:format和info:geo都是列族info的成员,列族前缀必须是”可打印的”,修饰符可以是任意字节,列族和修饰符用(:)分隔.</p>
<p>一个表的<em>列族</em>必须作为表模式的定义一部分<em>预先给出</em>,但<em>列组成员</em>可以随后按需加入.物理上,所有的<em>列族成员</em>都一起存放在文件系统中,HBase更确切地说是面向列族的存储器.调优和存储都是在列族层面上进行的,所以最好使所有列族成员有相同的访问模式和大小特征.<br><em>区域</em><br>HBase自动将表水平划分为区域,每个区域由表中行的子集构成,每个区域由他所属于的表,它包含的第一行和最后一行(不包括这行)来表示.一开始一个表只有一个区域,当区域大小超出设定的阈值是便会在某行的边界上分成<em>两个大小基本相同的新分区</em>,区域是在HBase集群上分布数据最小的单位,因为太大而无法存放在单台服务器上的表会被放到服务器集群上,每个节点负责管理所有区域的一个子集.在线的所有区域按次序排列就构成了表的所有内容.</p>
<p><em>加锁</em><br>HBase对行的更新是原子的</p>
<p><strong>实现</strong><br>Hbase = 1个master节点 + 多个regionserver从属机<br>主控机master负责启动一个全新的安装,把区域分配给注册的regionserver,恢复regionserver故障.<br>regionserver负责将0个或者多个区域的管理和响应客户端的读写请求.还负责区域划分并告知master有新的子区域.</p>
<p><img src="http://p5s7d12ls.bkt.clouddn.com/18-3-21/16805306.jpg" alt=""><br>HBase依赖于ZooKeeper,zookeeper集合体负责管理诸如hbase:meta目录表的位置以及当前集群主控机地址等重要信息.</p>
<p>HBase使用基于SSH的机制来运行远程命令,其配置方式类似于Hadoop,HBase通过Hadoop文件系统API来持久化存储数据,但在默认情况下,HBase会将存储写入本地文件系统,因此需要把它的存储配置指向要使用的HDFS集群.</p>
<p><em>运行中的HBase</em><br>HBase内部保留名为hbase:meta的特殊目录表,维护当前集群上所有区域的列表,状态和位置.区域变化时,目录表会重新进行相应的更新,这样集群上的信息状态就能保持是最新的.<br>新连接到zookeeper集群上的客户端首先查找hbase:meta位置,然后客户端通过查找合适的hbase:meta区域来获取用户空间区域所在节点和位置,接设客户端就可以直接和管理那个区域的regionserver交互.</p>
<p>每个行操作可能要访问三次远程节点,为节省代价,客户端会缓存hbase:meta时获取的信息.<br>到达regionserver的写操作首先追加到”提交日志”,然后加入内存中的memstore.如果memstore满,它的内容会刷入文件系统.</p>
<h2 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h2><p>配置好hbase后,可用mingling<code>hbase shell</code>进入shell,输入help可以查看命令列表.<br><em>创建一个表</em><br>要新建一个表,必须为表起一个名字,并为其定义模式,一个表的模式包含表的属性和列族的列表,列族本身也有属性.模式可以被修改,需要修改时用<code>disable</code>将其设为’离线’即可,<code>alter</code>命令可以进行修改,<code>enable</code>将表定义为在线.<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):002:0&gt; create 'test','data'</span><br><span class="line">0 row(s) in 1.2920 seconds</span><br></pre></td></tr></table></figure></p>
<p>新建一个名为test的表,只包含一个名为data的列,表和列族属性都为默认值.<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):003:0&gt; list</span><br><span class="line">TABLE</span><br><span class="line">test</span><br><span class="line">1 row(s) in 0.0110 seconds</span><br></pre></td></tr></table></figure></p>
<p>list输出所有表.<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):004:0&gt; put 'test','row1','data:1','value1'</span><br><span class="line">0 row(s) in 0.1720 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):005:0&gt; put 'test','row2','data:2','value2'</span><br><span class="line">0 row(s) in 0.0120 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):006:0&gt; put 'test','row3','data:3','valle3'</span><br><span class="line">0 row(s) in 0.0080 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):007:0&gt; get 'test','row1'</span><br><span class="line">COLUMN                        CELL</span><br><span class="line"> data:1                       timestamp=1521615103952, value=value1</span><br><span class="line">1 row(s) in 0.0250 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):008:0&gt; scan 'test'</span><br><span class="line">ROW                           COLUMN+CELL</span><br><span class="line"> row1                         column=data:1, timestamp=1521615103952, value=value1                              </span><br><span class="line"> row2                         column=data:2, timestamp=1521615113126, value=value2                              </span><br><span class="line"> row3                         column=data:3, timestamp=1521615131948, value=valle3                              </span><br><span class="line">3 row(s) in 0.0210 seconds</span><br></pre></td></tr></table></figure></p>
<p>在列表中三行插入数据,get获取第一行,scan预览表的内容.<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):003:0&gt; disable 'test'</span><br><span class="line">0 row(s) in 2.3790 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):004:0&gt; drop 'test'</span><br><span class="line">0 row(s) in 1.2580 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):005:0&gt; list</span><br><span class="line">TABLE</span><br><span class="line">0 row(s) in 0.0060 seconds</span><br></pre></td></tr></table></figure></p>
<p>删除表之前先禁用.</p>
<h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p><strong>Java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">       Configuration config = HBaseConfiguration.create();</span><br><span class="line">       Connection conn = ConnectionFactory.createConnection(config);</span><br><span class="line">       Admin admin  = conn.getAdmin();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            TableName tableName = TableName.valueOf(<span class="string">"test"</span>);</span><br><span class="line">            HTableDescriptor htd = <span class="keyword">new</span> HTableDescriptor(tableName);</span><br><span class="line">            HColumnDescriptor hcd = <span class="keyword">new</span> HColumnDescriptor(<span class="string">"data"</span>);</span><br><span class="line">            htd.addFamily(hcd);</span><br><span class="line">            admin.createTable(htd);</span><br><span class="line">            HTableDescriptor[] tables = admin.listTables();</span><br><span class="line">            <span class="keyword">if</span> (tables.length != <span class="number">1</span> &amp;&amp; Bytes.equals(tableName.getName(), tables[<span class="number">0</span>].getTableName().getName())) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Failed create of table"</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            Table table = conn.getTable(tableName);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">3</span>; i++) &#123;</span><br><span class="line">                    <span class="keyword">byte</span>[] row = Bytes.toBytes(<span class="string">"row"</span> + i);</span><br><span class="line">                    Put put = <span class="keyword">new</span> Put(row);</span><br><span class="line">                    <span class="keyword">byte</span>[] columnFalily = Bytes.toBytes(<span class="string">"data"</span>);</span><br><span class="line">                    <span class="keyword">byte</span>[] qualifier = Bytes.toBytes(String.valueOf(i));</span><br><span class="line">                    <span class="keyword">byte</span>[] value = Bytes.toBytes(<span class="string">"value"</span> + i);</span><br><span class="line">                    put.add(columnFalily, qualifier, value);</span><br><span class="line">                    table.put(put);</span><br><span class="line">                &#125;</span><br><span class="line">                Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string">"row1"</span>));</span><br><span class="line">                Result result = table.get(get);</span><br><span class="line">                System.out.println(<span class="string">"Get: "</span> + result);</span><br><span class="line">                Scan scan = <span class="keyword">new</span> Scan();<span class="comment">//scanner和cursor类似,不过在使用后要关闭</span></span><br><span class="line">                ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">for</span> (Result scannerResult : scanner) &#123;</span><br><span class="line">                        System.out.println(<span class="string">"Scan: "</span> + scannerResult);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    scanner.close();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//先禁用,再丢弃</span></span><br><span class="line">                admin.disableTable(tableName);</span><br><span class="line">                admin.deleteTable(tableName);</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                table.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            admin.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Configuration对象读入了程序classpath下hbase-site.xml等文件中的配置,客户端用ConnectionFactory创建了一个Connection对象,可以检索Admin和Table实例.Admin用于管理HBase集群,添加和丢弃表,Table用于访问指定的表.</p>
<p><strong>MapReduce</strong><br>HBase可以作为MR的源和输出,TableInputFormat类可以在区域边界进行分隔,使map能够拿到单个的区域进行处理,TableOutputFormat将把reduce的结果写入HBase;<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleRowCounter</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RowCounterMapper</span> <span class="keyword">extends</span> <span class="title">TableMapper</span>&lt;<span class="title">ImmutableBytesWritable</span>, <span class="title">Result</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">enum</span> Counters &#123; Rows &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(ImmutableBytesWritable key, Result value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            context.getCounter(Counters.Rows).increment(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (args.length != <span class="number">1</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"Usage SimpleRowCounter &lt;tablename&gt;"</span>);</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String tableName = args[<span class="number">0</span>];</span><br><span class="line">        Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">        scan.setFilter(<span class="keyword">new</span> FirstKeyOnlyFilter());</span><br><span class="line">        Job job  = <span class="keyword">new</span> Job(getConf(), getClass().getSimpleName());</span><br><span class="line">        job.setJarByClass(getClass());</span><br><span class="line">        TableMapReduceUtil.initTableMapperJob(tableName, scan, RowCounterMapper.class, ImmutableBytesWritable.class, Result.class, job);</span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line">        job.setOutputFormatClass(NullOutputFormat.class);</span><br><span class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> exitCode = ToolRunner.run(HBaseConfiguration.create(), <span class="keyword">new</span> SimpleRowCounter(), args);</span><br><span class="line">        System.exit(exitCode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p> TableMapper是MR.Mapper的特化,他设定map输入类型由TableInputFormat来传递,输入键为ImmutableBytesWritable(行键), 值为Result(扫描行结果).TableMapReduceUtil.initTableMapperJob()对作业进行配置.</p>
<p><strong>加载数据</strong>将要写入的数据库必须在作业配置中通过设置TableOutoputFormat.OUTPUTTABLE属性来指定.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">job.getConfiguration().set(TableOutputFormat.OUTPUT_TABLE, <span class="string">"observations"</span>);</span><br><span class="line">job.setMapperClass(HBaseTemperatureMapper.class);</span><br><span class="line">job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line">job.setOutputFormatClass(TableOutputFormat.class);</span><br></pre></td></tr></table></figure></p>
<p><em>批量加载</em><br>HBase有批量加载(bulk loading)工具,他从MR把以内部格式表示的数据直接写入文件系统,从而实现批量加载.这样比用API写入数据的方式快至少一个数量级.</p>
<blockquote>
<p>在使用Jar包向hbase加载数据时会出现如下错误<br>2018-03-21 20:38:01,165 INFO  [main] mapreduce.Job: Running job: job_1521635550341_0002<br>2018-03-21 20:38:06,216 INFO  [main] mapreduce.Job: Job job_1521635550341_0002 running in uber mode : false<br>2018-03-21 20:38:06,217 INFO  [main] mapreduce.Job:  map 0% reduce 0%<br>2018-03-21 20:38:06,234 INFO  [main] mapreduce.Job: doop.util.Shell.run(Shell.java:869)<br>        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170)<br>        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236)<br>        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305)<br>        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84)<br>        at java.util.concurrent.FutureTask.run(FutureTask.java:266)<br>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)<br>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)<br>        at java.lang.Thread.run(Thread.java:748)<br>解决办法:yarn-site.xml的yarn.application.classpath配置项中，加上hbase相关的jar包。</p>
</blockquote>
<p>Container exited with a non-zero exit code 1<br>For more detailed output, check the application tracking page: http://<strong><strong>*</strong></strong>:8088/cluster/app/application_1521635550341_0002 Then click on links to logs of each attempt.<br>. Failing the application.</p>
<p>批量加载过程:</p>
<ol>
<li>使用HFileOutputFormat2通过一个MR作业将HFile写入HDFS目录</li>
<li>将HFiles从HDFS一如现有的HBase表中,该表在此过程可以是活跃的</li>
</ol>
<h2 id="HBase和RDBMS比较"><a href="#HBase和RDBMS比较" class="headerlink" title="HBase和RDBMS比较"></a>HBase和RDBMS比较</h2><p>HBASE:<br>分布式,面向列的数据存储系统,在HDFS上提供随机读写,聚焦于各种可伸缩问题,表可以很宽,很高,水平分区在上千个普通商用机节点复制.<br>RDBMS:<br>模式固定, 面向行,ACID性质,扩展性不强</p>

  </section>
</article>

  <div class="sharing grid">
  <section class="profile grid-item grid">
    <img class="avatar" src="http://7xrcp8.com1.z0.glb.clouddn.com/avatar.png" alt="avatar" />
    <div class="grid-item">
      <p class="title"> lyyourc </p>
      <p class="subtitle"> You Are The JavaScript In My HTML </p>
    <div>
  </section>

  <section class="share-btns">
    <!-- <p> share it if you like it~ </p> -->
    <a
  class="twitter-share-button"
  data-size="large"
  data-via="DrakeLeung"
  href="https://twitter.com/intent/tweet?text=HBase是一个在HDFS上开发的面向列"
>
  Tweet
</a>

<script>
  window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  js.async = true;
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));
</script>

  </section>
</div>


  
    
<section class="article-comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

<script>
  var disqus_shortname = 'drakeleung';
  
  var disqus_url = '//harold.me/2018/03/21/关于HBase/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


  
</main>

</body>
</html>
